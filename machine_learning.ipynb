{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make-o-Matic Gesture Recognition\n",
    "\n",
    "## Part 3: Machine Learning\n",
    "\n",
    "2017 by Thomas Lidy, TU Wien\n",
    "\n",
    "### Requirements\n",
    "\n",
    "Python 2.7\n",
    "\n",
    "pip install -r requirements.txt\n",
    "\n",
    "Tested on OS: Ubuntu 16.04.3 LTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time # for time measuring\n",
    "import datetime # for time printing\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.signal import resample\n",
    "# Power spectral density using a periodogram\n",
    "from scipy.signal import periodogram\n",
    "\n",
    "from collections import Counter # for majority vote\n",
    "from collections import OrderedDict # for color palette\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def str_to_int(string):\n",
    "    '''cut away first character and convert to int - used to convert Gesture IDs like \"G01\" to 1'''\n",
    "    return int(string[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timestr(seconds):\n",
    "    ''' returns HH:MM:ss formatted time string for given seconds\n",
    "    (seconds can be a float with milliseconds included, but only the integer part will be used)\n",
    "    :return: string\n",
    "    '''\n",
    "    return str(datetime.timedelta(seconds=int(seconds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Meta-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# main data\n",
    "\n",
    "# original input\n",
    "#csv_file = 'data/EXPORT_09042017173622.csv'\n",
    "\n",
    "# preprocessed input\n",
    "csv_file = 'data/EXPORT_09042017173622_preprocessed.csv'\n",
    "\n",
    "\n",
    "# json files to translate gestures, parcours into long text\n",
    "#gestures_file = 'data/gestures.json' # this is the file edited manually by us to conform to json\n",
    "gestures_file = 'data/gestures.json.orig' # this is the file edited manually by us to conform to json\n",
    "parcours_file = 'data/parcours.json'\n",
    "mutations_file = 'data/mutations.json'\n",
    "\n",
    "files = (gestures_file, parcours_file, mutations_file)\n",
    "dataframes = []\n",
    "\n",
    "# NOTE THAT THESE JSON FILES ARE NOT JSON CONFORM\n",
    "# each line is a json string on its own, so we need to process the json line by line and combine THEN into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oid(oid_dict):\n",
    "    # get from the original representation {u'$oid': u'589c8ed31337b5ab1e1be121'} just the oid\n",
    "    return oid_dict['$oid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get meta-files with descriptions of gestures, parcours and mutations\n",
    "for filename in files:\n",
    "    with open(filename) as f:\n",
    "        lines = [line.rstrip('\\n') for line in f]   # .decode(\"utf-8\")\n",
    "\n",
    "    lines = [json.loads(line) for line in lines]\n",
    "    \n",
    "    # convert list of json lines into Dataframe\n",
    "    df = pd.DataFrame.from_dict(lines)\n",
    "    \n",
    "    # convert long $oid to short\n",
    "    df['_id'] = df['_id'].apply(get_oid)\n",
    "    \n",
    "    # set the real id\n",
    "    df.set_index('id', inplace=True)\n",
    "    \n",
    "    # convert index (ID) from string like 'G01' to int\n",
    "    df.index = df.index.map(str_to_int)\n",
    "    \n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(gestures_df, parcours_df, mutations_df) = tuple(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>isGarbage</th>\n",
       "      <th>isNesture</th>\n",
       "      <th>name</th>\n",
       "      <th>slug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58a23a22d826756404709446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single Rotation klein rechtsrum</td>\n",
       "      <td>rssr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58a23a22d826756404709447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single Rotation klein linksrum</td>\n",
       "      <td>rssl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58a23a22d826756404709448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oszillierende Rotation klein rechtsrum</td>\n",
       "      <td>rosr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58a23a22d826756404709449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oszillierende Rotation klein linksrum</td>\n",
       "      <td>rosl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58a23a22d82675640470944a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single Rotation groß rechtsrum</td>\n",
       "      <td>rsbr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58a23a22d82675640470944b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single Rotation groß linksrum</td>\n",
       "      <td>rsbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58a23a22d82675640470944c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oszillierende Rotation groß rechtsrum</td>\n",
       "      <td>robr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58a23a22d82675640470944d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oszillierende Rotation groß linksrum</td>\n",
       "      <td>robl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58a23a22d82675640470944e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kontinuierliche Rotation groß rechtsrum</td>\n",
       "      <td>rcbr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>58a23a22d82675640470944f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kontinuierliche Rotation groß linksrum</td>\n",
       "      <td>rcbl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>58a23a22d826756404709450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LinearMovement Single</td>\n",
       "      <td>lms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>58a23a22d826756404709451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LinearMovement Oszillierend</td>\n",
       "      <td>lmo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>58a23a22d826756404709452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drücken</td>\n",
       "      <td>pb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58a23a22d826756404709453</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Rest</td>\n",
       "      <td>rest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>58a23a22d826756404709454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Greifen</td>\n",
       "      <td>grasp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>58a23a22d826756404709455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Positionieren</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>58a23a22d826756404709456</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Umgreifen</td>\n",
       "      <td>regr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58a23a22d826756404709457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>Ablegen</td>\n",
       "      <td>release</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         _id isGarbage isNesture  \\\n",
       "1   58a23a22d826756404709446       NaN       NaN   \n",
       "2   58a23a22d826756404709447       NaN       NaN   \n",
       "3   58a23a22d826756404709448       NaN       NaN   \n",
       "4   58a23a22d826756404709449       NaN       NaN   \n",
       "5   58a23a22d82675640470944a       NaN       NaN   \n",
       "6   58a23a22d82675640470944b       NaN       NaN   \n",
       "7   58a23a22d82675640470944c       NaN       NaN   \n",
       "8   58a23a22d82675640470944d       NaN       NaN   \n",
       "9   58a23a22d82675640470944e       NaN       NaN   \n",
       "10  58a23a22d82675640470944f       NaN       NaN   \n",
       "11  58a23a22d826756404709450       NaN       NaN   \n",
       "12  58a23a22d826756404709451       NaN       NaN   \n",
       "13  58a23a22d826756404709452       NaN       NaN   \n",
       "14  58a23a22d826756404709453      True      True   \n",
       "15  58a23a22d826756404709454       NaN      True   \n",
       "16  58a23a22d826756404709455       NaN      True   \n",
       "17  58a23a22d826756404709456       NaN      True   \n",
       "18  58a23a22d826756404709457       NaN      True   \n",
       "\n",
       "                                       name     slug  \n",
       "1           Single Rotation klein rechtsrum     rssr  \n",
       "2            Single Rotation klein linksrum     rssl  \n",
       "3    Oszillierende Rotation klein rechtsrum     rosr  \n",
       "4     Oszillierende Rotation klein linksrum     rosl  \n",
       "5            Single Rotation groß rechtsrum     rsbr  \n",
       "6             Single Rotation groß linksrum     rsbl  \n",
       "7     Oszillierende Rotation groß rechtsrum     robr  \n",
       "8      Oszillierende Rotation groß linksrum     robl  \n",
       "9   Kontinuierliche Rotation groß rechtsrum     rcbr  \n",
       "10   Kontinuierliche Rotation groß linksrum     rcbl  \n",
       "11                    LinearMovement Single      lms  \n",
       "12              LinearMovement Oszillierend      lmo  \n",
       "13                                  Drücken       pb  \n",
       "14                                     Rest     rest  \n",
       "15                                  Greifen    grasp  \n",
       "16                            Positionieren      pos  \n",
       "17                                Umgreifen     regr  \n",
       "18                                  Ablegen  release  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gestures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"positive\" gestures to recognize (not nestures)\n",
    "gestures_pos = gestures_df[gestures_df['isNesture'] != True].index.tolist()\n",
    "gestures_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 15, 16, 17, 18]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"negative\" gestures (nestures)\n",
    "gestures_neg = gestures_df[gestures_df['isNesture'] == True].index.tolist()\n",
    "nestures = gestures_neg # synonym\n",
    "gestures_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define handy function shortcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gesture_name(gesture_id):\n",
    "    if gesture_id is None: return None\n",
    "    return gestures_df.loc[gesture_id,'name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Experiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trainset</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Subject</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>RFID</th>\n",
       "      <th>GRASP_A</th>\n",
       "      <th>GRASP_B</th>\n",
       "      <th>GRASP_C</th>\n",
       "      <th>AX</th>\n",
       "      <th>AY</th>\n",
       "      <th>AZ</th>\n",
       "      <th>EX</th>\n",
       "      <th>EY</th>\n",
       "      <th>EZ</th>\n",
       "      <th>Parcours</th>\n",
       "      <th>Parcours_Step</th>\n",
       "      <th>Mutation</th>\n",
       "      <th>Host</th>\n",
       "      <th>Host/Spot</th>\n",
       "      <th>Gesture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>0</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>781</td>\n",
       "      <td>8</td>\n",
       "      <td>797</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>216.8125</td>\n",
       "      <td>9.0625</td>\n",
       "      <td>-81.9375</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>29001</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>782</td>\n",
       "      <td>0</td>\n",
       "      <td>799</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>217.0625</td>\n",
       "      <td>9.0625</td>\n",
       "      <td>-81.9375</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>46136</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>782</td>\n",
       "      <td>6</td>\n",
       "      <td>798</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>217.4375</td>\n",
       "      <td>9.1250</td>\n",
       "      <td>-81.8750</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>74902</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>784</td>\n",
       "      <td>7</td>\n",
       "      <td>798</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>217.6250</td>\n",
       "      <td>9.1250</td>\n",
       "      <td>-81.8125</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>97663</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>781</td>\n",
       "      <td>0</td>\n",
       "      <td>798</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>217.9375</td>\n",
       "      <td>9.1875</td>\n",
       "      <td>-81.7500</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>116448</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>784</td>\n",
       "      <td>4</td>\n",
       "      <td>800</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>218.3125</td>\n",
       "      <td>9.2500</td>\n",
       "      <td>-81.7500</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>148753</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>783</td>\n",
       "      <td>0</td>\n",
       "      <td>798</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>218.5000</td>\n",
       "      <td>9.3125</td>\n",
       "      <td>-81.7500</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>167422</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>784</td>\n",
       "      <td>2</td>\n",
       "      <td>798</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>218.6875</td>\n",
       "      <td>9.3750</td>\n",
       "      <td>-81.7500</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>187481</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>782</td>\n",
       "      <td>4</td>\n",
       "      <td>799</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>219.0000</td>\n",
       "      <td>9.4375</td>\n",
       "      <td>-81.7500</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>_TRAINSET14022017094616</td>\n",
       "      <td>1</td>\n",
       "      <td>Andreas</td>\n",
       "      <td>213733</td>\n",
       "      <td>000000000000</td>\n",
       "      <td>784</td>\n",
       "      <td>13</td>\n",
       "      <td>799</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>219.1250</td>\n",
       "      <td>9.4375</td>\n",
       "      <td>-81.7500</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Trainset  Experiment  Subject  TimeStamp          RFID  \\\n",
       "0  _TRAINSET14022017094616           1  Andreas          0  000000000000   \n",
       "1  _TRAINSET14022017094616           1  Andreas      29001  000000000000   \n",
       "2  _TRAINSET14022017094616           1  Andreas      46136  000000000000   \n",
       "3  _TRAINSET14022017094616           1  Andreas      74902  000000000000   \n",
       "4  _TRAINSET14022017094616           1  Andreas      97663  000000000000   \n",
       "5  _TRAINSET14022017094616           1  Andreas     116448  000000000000   \n",
       "6  _TRAINSET14022017094616           1  Andreas     148753  000000000000   \n",
       "7  _TRAINSET14022017094616           1  Andreas     167422  000000000000   \n",
       "8  _TRAINSET14022017094616           1  Andreas     187481  000000000000   \n",
       "9  _TRAINSET14022017094616           1  Andreas     213733  000000000000   \n",
       "\n",
       "   GRASP_A  GRASP_B  GRASP_C    AX    AY    AZ        EX      EY       EZ  \\\n",
       "0      781        8      797  0.06 -0.02 -0.10  216.8125  9.0625 -81.9375   \n",
       "1      782        0      799  0.09 -0.04 -0.11  217.0625  9.0625 -81.9375   \n",
       "2      782        6      798  0.12 -0.09  0.09  217.4375  9.1250 -81.8750   \n",
       "3      784        7      798  0.08 -0.08  0.03  217.6250  9.1250 -81.8125   \n",
       "4      781        0      798  0.07 -0.09  0.04  217.9375  9.1875 -81.7500   \n",
       "5      784        4      800  0.12 -0.06 -0.03  218.3125  9.2500 -81.7500   \n",
       "6      783        0      798  0.21 -0.04  0.03  218.5000  9.3125 -81.7500   \n",
       "7      784        2      798  0.18 -0.10 -0.08  218.6875  9.3750 -81.7500   \n",
       "8      782        4      799  0.15 -0.18 -0.03  219.0000  9.4375 -81.7500   \n",
       "9      784       13      799  0.15 -0.18 -0.17  219.1250  9.4375 -81.7500   \n",
       "\n",
       "   Parcours  Parcours_Step  Mutation  Host Host/Spot  Gesture  \n",
       "0       101              1       151     8       NaN       15  \n",
       "1       101              1       151     8       NaN       15  \n",
       "2       101              1       151     8       NaN       15  \n",
       "3       101              1       151     8       NaN       15  \n",
       "4       101              1       151     8       NaN       15  \n",
       "5       101              1       151     8       NaN       15  \n",
       "6       101              1       151     8       NaN       15  \n",
       "7       101              1       151     8       NaN       15  \n",
       "8       101              1       151     8       NaN       15  \n",
       "9       101              1       151     8       NaN       15  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Experiment Data\n",
    "data = pd.read_csv(csv_file)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the TimeStamp Diffs \n",
    "# (TimeStamps are reset after each Parcours, so we have to do it groupwise by Parcours)\n",
    "group_by = ('Subject','Experiment','Trainset','Parcours')\n",
    "timestamp_deltas = data.groupby(group_by)['TimeStamp'].diff()\n",
    "#timestamp_deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7.108210e+05\n",
       "mean     2.586989e+04\n",
       "std      3.509427e+04\n",
       "min      1.930000e+02\n",
       "25%      1.757400e+04\n",
       "50%      2.400500e+04\n",
       "75%      2.863500e+04\n",
       "max      5.743871e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_deltas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: Not sure why there is a value of 5,743,871 as the max timestamp delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Stamp delta and Sample Rate of Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time stamp deltas are on median 24005.0 micro-seconds\n"
     ]
    }
   ],
   "source": [
    "time_delta = timestamp_deltas.median()\n",
    "print \"Time stamp deltas are on median\", time_delta, \"micro-seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024005"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_delta_sec = time_delta / 1000000  # microsec to sec\n",
    "time_delta_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal sampling rate is on avg. 41.6579879192 Hz\n"
     ]
    }
   ],
   "source": [
    "sampling_rate = 1 /  time_delta_sec   \n",
    "print \"Signal sampling rate is on avg.\", sampling_rate, \"Hz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: Pandas group_by can be used instead of a for loop, to loop over groups of objects in the data, \n",
    "# e.g. all data in a parcours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject  Experiment  Trainset                 Parcours\n",
       "Alfred   2           _TRAINSET14022017144824  101              [15, 1, 17]\n",
       "                     _TRAINSET14022017144923  102              [15, 2, 17]\n",
       "                     _TRAINSET14022017145122  103               [15, 1, 2]\n",
       "                     _TRAINSET14022017145237  104               [15, 2, 1]\n",
       "                     _TRAINSET14022017145434  107              [15, 1, 17]\n",
       "                     _TRAINSET14022017145514  108              [15, 2, 17]\n",
       "                     _TRAINSET14022017145629  109               [15, 1, 2]\n",
       "                     _TRAINSET14022017145751  110               [15, 2, 1]\n",
       "                     _TRAINSET14022017145913  113              [15, 1, 17]\n",
       "                     _TRAINSET14022017145944  114              [15, 2, 17]\n",
       "                     _TRAINSET14022017150026  115               [15, 1, 2]\n",
       "                     _TRAINSET14022017150110  116               [15, 2, 1]\n",
       "                     _TRAINSET14022017150614  401               [15, 6, 5]\n",
       "                     _TRAINSET14022017150702  402               [15, 6, 5]\n",
       "                     _TRAINSET14022017150748  403               [15, 6, 5]\n",
       "                     _TRAINSET14022017151539  201          [15, 16, 1, 17]\n",
       "                     _TRAINSET14022017151631  202          [15, 16, 2, 17]\n",
       "                     _TRAINSET14022017151826  203           [15, 16, 1, 2]\n",
       "                     _TRAINSET14022017151945  206          [15, 16, 1, 17]\n",
       "                     _TRAINSET14022017152030  207          [15, 16, 2, 17]\n",
       "                     _TRAINSET14022017152128  208           [15, 16, 1, 2]\n",
       "                     _TRAINSET14022017152424  211          [15, 16, 1, 17]\n",
       "                     _TRAINSET14022017152511  212          [15, 16, 2, 17]\n",
       "                     _TRAINSET14022017152553  213           [15, 16, 1, 2]\n",
       "                     _TRAINSET14022017152806  216          [15, 16, 1, 17]\n",
       "                     _TRAINSET14022017152849  217          [15, 16, 2, 17]\n",
       "                     _TRAINSET14022017153027  218           [15, 16, 1, 2]\n",
       "                     _TRAINSET14022017153200  221          [15, 16, 1, 17]\n",
       "                     _TRAINSET14022017153244  222          [15, 16, 2, 17]\n",
       "                     _TRAINSET14022017153321  223           [15, 16, 1, 2]\n",
       "                                                                ...       \n",
       "Dominik  7           _TRAINSET18022017101515  233           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017101716  234           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017102015  235           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017102241  236           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017102722  717             [15, 16, 12]\n",
       "                     _TRAINSET18022017102940  718             [15, 16, 12]\n",
       "                     _TRAINSET18022017103121  719             [15, 16, 12]\n",
       "                     _TRAINSET18022017103231  720             [15, 16, 12]\n",
       "                     _TRAINSET18022017103415  721             [15, 16, 12]\n",
       "                     _TRAINSET18022017103540  722             [15, 16, 12]\n",
       "                     _TRAINSET18022017103651  723             [15, 16, 12]\n",
       "                     _TRAINSET18022017103813  724             [15, 16, 12]\n",
       "                     _TRAINSET18022017105413  626           [15, 16, 7, 8]\n",
       "                     _TRAINSET18022017105840  627           [15, 16, 7, 8]\n",
       "                     _TRAINSET18022017110223  628           [15, 16, 7, 8]\n",
       "                     _TRAINSET18022017110459  629           [15, 16, 7, 8]\n",
       "                     _TRAINSET18022017110836  630           [15, 16, 7, 8]\n",
       "                     _TRAINSET18022017111316  331           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017111515  332           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017111659  333           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017111827  334           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017112005  335           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017112412  336           [15, 16, 3, 4]\n",
       "                     _TRAINSET18022017113146  901         [15, 14, 13, 16]\n",
       "                     _TRAINSET18022017113300  901         [15, 14, 13, 16]\n",
       "                     _TRAINSET18022017113500  901         [15, 14, 13, 16]\n",
       "                     _TRAINSET18022017113556  901         [15, 14, 13, 16]\n",
       "                     _TRAINSET18022017113729  901         [15, 14, 13, 16]\n",
       "                     _TRAINSET18022017114050  902                 [15, 11]\n",
       "                     _TRAINSET18022017114128  903                 [15, 11]\n",
       "Name: Gesture, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see gestures per Parcours\n",
    "group_by = ('Subject','Experiment','Trainset','Parcours')\n",
    "data.groupby(group_by)['Gesture'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject  Experiment  Trainset                 Parcours  Parcours_Step\n",
       "Alfred   2           _TRAINSET14022017144824  101       1                [15]\n",
       "                                                        2                 [1]\n",
       "                                                        3                [17]\n",
       "                                                        4                 [1]\n",
       "                                                        5                [17]\n",
       "                                                        6                 [1]\n",
       "                                                        7                [17]\n",
       "                                                        8                 [1]\n",
       "                                                        9                [17]\n",
       "                                                        10                [1]\n",
       "                     _TRAINSET14022017144923  102       1                [15]\n",
       "                                                        2                 [2]\n",
       "                                                        3                [17]\n",
       "                                                        4                 [2]\n",
       "                                                        5                [17]\n",
       "                                                        6                 [2]\n",
       "                                                        7                [17]\n",
       "                                                        8                 [2]\n",
       "                                                        9                [15]\n",
       "                                                        10                [2]\n",
       "                     _TRAINSET14022017145122  103       1                [15]\n",
       "                                                        2                 [1]\n",
       "                                                        3                 [2]\n",
       "                                                        4                 [1]\n",
       "                                                        5                 [2]\n",
       "                                                        6                 [1]\n",
       "                                                        7                 [2]\n",
       "                                                        8                 [1]\n",
       "                                                        9                 [2]\n",
       "                                                        10                [1]\n",
       "                                                                         ... \n",
       "Dominik  7           _TRAINSET18022017113729  901       2                [14]\n",
       "                                                        4                [13]\n",
       "                                                        5                [16]\n",
       "                                                        6                [14]\n",
       "                                                        8                [13]\n",
       "                                                        9                [16]\n",
       "                                                        10               [14]\n",
       "                                                        12               [13]\n",
       "                     _TRAINSET18022017114050  902       1                [15]\n",
       "                                                        2                [11]\n",
       "                                                        3                [11]\n",
       "                                                        4                [11]\n",
       "                                                        5                [11]\n",
       "                                                        6                [11]\n",
       "                                                        7                [11]\n",
       "                                                        8                [11]\n",
       "                                                        9                [11]\n",
       "                                                        10               [11]\n",
       "                                                        11               [11]\n",
       "                     _TRAINSET18022017114128  903       1                [15]\n",
       "                                                        2                [11]\n",
       "                                                        3                [11]\n",
       "                                                        4                [11]\n",
       "                                                        5                [11]\n",
       "                                                        6                [11]\n",
       "                                                        7                [11]\n",
       "                                                        8                [11]\n",
       "                                                        9                [11]\n",
       "                                                        10               [11]\n",
       "                                                        11               [11]\n",
       "Name: Gesture, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see gestures per Parcours Step\n",
    "group_by = ('Subject','Experiment','Trainset','Parcours','Parcours_Step')\n",
    "data.groupby(group_by)['Gesture'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Nestures\n",
    "\n",
    "choose whether to replace, i.e. merge nestures by their closest (following) gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_nestures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originally 5169 individual gesture blocks\n"
     ]
    }
   ],
   "source": [
    "group_by = ('Subject','Experiment','Trainset','Parcours','Parcours_Step','Mutation','Gesture')\n",
    "group_df = data.groupby(group_by)\n",
    "print \"Originally\", len(group_df), \"individual gesture blocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.groupby(group_by).count().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Therefore Group by PARCOURS\n",
    "# group data nicely, subdivided by Subject, Experiment, Trainset, Parcours\n",
    "group_by = ('Subject','Experiment','Trainset','Parcours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1: replace ALL Nestures by NaN\n",
    "if replace_nestures:\n",
    "    # make a copy of the complete data before altering anything\n",
    "    data_nonest = data.copy()\n",
    "    idx_nestures = data_nonest['Gesture'].isin(nestures)\n",
    "    # replace nestures by NaN\n",
    "    data_nonest.loc[idx_nestures,'Gesture'] = np.nan\n",
    "    print data_nonest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we can use the Forward FILL and Backward FILL methods of Pandas\n",
    "# to replace the NaNs by the values that come before or after\n",
    "\n",
    "# BUT: we shall not do that across Parcours/Experiments!\n",
    "# GROUPBY helps us here to apply the fill methods only within a PARCOURS\n",
    "\n",
    "if replace_nestures:\n",
    "    # BACKWARD FILL first by later values to NaNs before\n",
    "    data_nonest = data_nonest.groupby(group_by).bfill()\n",
    "\n",
    "    # in case there would be NaNs left, do also a FORWARD FILL\n",
    "    #data = data.groupby(group_by).ffill()\n",
    "    \n",
    "    print \"Replaced Nestures by filling with neighboured Gestures!\"\n",
    "    print np.isnan(data_nonest['Gesture']).sum(), \"NaN values remaining. Should be 0.\"\n",
    "    # NOTE: bfill applies to ALL COLUMNS! so there might be other columns affected by this!\n",
    "    # TODO double-check any side effects!\n",
    "    \n",
    "    # adding NaNs cause the Gesture column to be converted from int to float\n",
    "    # we convert back to int\n",
    "    data_nonest['Gesture'] = data_nonest['Gesture'].astype(int)\n",
    "    \n",
    "    # check/verify via groupby:\n",
    "    group_by = ('Subject','Experiment','Trainset','Parcours','Gesture')\n",
    "    group_df = data_nonest.groupby(group_by)\n",
    "    print \"After nesture replacement\", len(group_df), \"individual gesture blocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#group_df.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from here on we use data again for data_nonest\n",
    "\n",
    "if replace_nestures:\n",
    "    # keep original data in a variable\n",
    "    data_orig = data\n",
    "    data = data_nonest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Procssing Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which Sensor Parameters to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include_GRASP = True\n",
    "\n",
    "if include_GRASP:\n",
    "    params = ['AX', 'AY', 'AZ', 'EX', 'EY', 'EZ', 'GRASP_A', 'GRASP_B', 'GRASP_C']\n",
    "else:\n",
    "    params = ['AX', 'AY', 'AZ', 'EX', 'EY', 'EZ']\n",
    "\n",
    "# TODO add RFID?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Normalize?\n",
    "\n",
    "#### Normalize Parameter columns to -1, 1\n",
    "\n",
    "here it's done globally. if set to False, there is an option to do it locally later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalize_global = True\n",
    "# normalize_global means we normalize all parameter columns at once, globally => NO LATER TREATMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[params].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if normalize_global:\n",
    "    # normalize to -1, 1\n",
    "    data[params] = preprocessing.minmax_scale(data[params], feature_range=(-1, 1), axis=0, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[params].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get Isolated Gestures\n",
    "\n",
    "### Grouping for each Gesture:\n",
    "\n",
    "### Select correct level of detail:\n",
    "* a) Parcours: all same gestures of a Parcours will be concatenated together\n",
    "* b) Parcours-Step: gestures inside one Parcours will be keep individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select: 'Parcours' or 'Parcours_Step':\n",
    "#level_of_detail = 'Parcours'\n",
    "level_of_detail = 'Parcours-Step' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GET INDIVIDUAL GESTURES \n",
    "# group data nicely, subdivided by Subject, Experiment, Trainset, Parcours or Parcours-Step, Gesture\n",
    "\n",
    "if level_of_detail == 'Parcours':\n",
    "    group_by = ('Subject','Experiment','Trainset','Parcours','Gesture')\n",
    "elif level_of_detail == 'Parcours-Step':\n",
    "    group_by = ('Subject','Experiment','Trainset','Parcours','Parcours_Step','Gesture')\n",
    "else:\n",
    "    raise ValueError(\"invalid level_of_detail\")\n",
    "    \n",
    "group_df = data.groupby(group_by)\n",
    "group_df.mean().head(100)  # mean is not meaningful here as aggregation - just to print the structure of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(group_df), \"individual gesture blocks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Gesture Data: 1 Block per each individual Gesture\n",
    "\n",
    "we put each time series that belong to 1 particular gesture in a particular parcours into a dictionary,\n",
    "which contains a list of such time series blocks per gesture entry in the dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Gesture Dictionary + Reduce Data to desired parameter columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we ITERATE nicely through group_df and get each Gesture block individually\n",
    "# -> group_data will be a dataframe just for a single gesture\n",
    "\n",
    "i=0\n",
    "# dictionary containing a list of sub-datasets for each gesture, to train ML\n",
    "gesture_exp_dict = {}\n",
    "\n",
    "for name_tuple, datablock in group_df:\n",
    "    i += 1\n",
    "    #print str(name_tuple)\n",
    "    gesture = name_tuple[-1]  # gesture is last element of tuple, as defined in group_by above\n",
    "    \n",
    "    # initalize empty list for the gesture if not existing in dict yet\n",
    "    if gesture not in gesture_exp_dict.keys():\n",
    "        gesture_exp_dict[gesture] = [] \n",
    "        \n",
    "    # reduce dataframe to params columns\n",
    "    datablock = datablock[params] \n",
    "    \n",
    "    # add data to gesture dict\n",
    "    gesture_exp_dict[gesture].append(datablock)\n",
    "    \n",
    "    # NOTE that group_data here still contains ALL data columns. we will redue to params later\n",
    "\n",
    "print \"DONE:\", i, \"gesture blocks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Statistics about the Gesture Block data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many data blocks = training examples do we have for each gesture\n",
    "for gest in sorted(gesture_exp_dict.keys()):\n",
    "    print \"G\", gest, '\\t', len(gesture_exp_dict[gest]), \"training data blocks\", '\\t', gesture_name(gest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how many data points (= samples or timesteps) does each data block have?\n",
    "\n",
    "data_sizes = {} # collect per gesture in dict\n",
    "data_sizes_total = [] # collect all in list\n",
    "\n",
    "print \"Average length per gesture:\"\n",
    "\n",
    "for gest in sorted(gesture_exp_dict.keys()):\n",
    "    print \"G\", gest, ':\\t', \n",
    "    data_sizes[gest] = []\n",
    "    for datablock in gesture_exp_dict[gest]:\n",
    "        size = datablock.shape[0]\n",
    "        data_sizes[gest].append(size)\n",
    "        data_sizes_total.append(size)\n",
    "    avg_gesture_len = int(np.mean(data_sizes[gest]))\n",
    "    print \"% d samples \\t%0.2f sec\" % (avg_gesture_len, avg_gesture_len * time_delta_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# minimum, average and maximum sample size of gestures\n",
    "gest_len_min = min(data_sizes_total)\n",
    "gest_len_avg = np.mean(data_sizes_total)\n",
    "gest_len_max = max(data_sizes_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gest_len_min, gest_len_avg, gest_len_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# average data length (number of samples)\n",
    "print \"Average length all gestures\"\n",
    "print \"% d samples \\t%0.2f sec\" % (gest_len_avg, gest_len_avg * time_delta_sec)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.Series(data_sizes_total).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low-Pass Filter\n",
    "\n",
    "removing high frequencies (little fluctuations which are probably not relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# source code from https://stackoverflow.com/questions/25191620/creating-lowpass-filter-in-scipy-understanding-methods-and-units\n",
    "\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    '''cutoff: cutoff frequency in Hz\n",
    "    fs: sampling rate in Hz'''\n",
    "    nyq = 0.5 * fs # Nyquist frequency is half the sampling rate (fs)\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Filter Settings here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter settings (global vars)\n",
    "\n",
    "# filter order (see scipy: butter)\n",
    "order = 1 #3 #5 #6\n",
    "\n",
    "# sampling rate in Hz\n",
    "#fs = 30.0       # fixed assumed sample rate\n",
    "fs = sampling_rate   # determined before by average time delta \n",
    "\n",
    "# cutoff frequency of the filter in Hz\n",
    "cutoff = 4 #Hz\n",
    "#cutoff = 3.667 \n",
    "#cutoff = 1.3\n",
    "#cutoff = 0.667 \n",
    "#cutoff = 0.5\n",
    "#cutoff = 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_signal(testdata, \n",
    "                      normalize=False, \n",
    "                      resampling=False, n_samples=None, timestamps=None, window='hann', \n",
    "                      filtering=False):\n",
    "    \n",
    "    # Min/max normalization\n",
    "    # Note: to do it the fully right way, the minmax scaling should be done on all training data coherently\n",
    "    # (currently its done per training block) and the same scaling values (min and max) should be reused here\n",
    "    # see http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "    if normalize:\n",
    "        testdata = preprocessing.minmax_scale(testdata, feature_range=(-1, 1), axis=0)\n",
    "        \n",
    "    # Time Resampling\n",
    "    if resampling:\n",
    "        \n",
    "        if n_samples is None:\n",
    "            # if not a FIXED number of samples is provided, the number of samples stays the same as in the input signal\n",
    "            n_samples = testdata.shape[0] \n",
    "        \n",
    "        if timestamps is None:\n",
    "            # NO timestamp alignment, just resampling to a given number of target samples\n",
    "            testdata = resample(testdata, num=n_samples, window=window)\n",
    "        else:\n",
    "            # if provided, we use the original timestamps to re-align the signal\n",
    "            # TODO check: length of signals in testdata must match len(timestamps)\n",
    "            testdata, timestamps2 = resample(testdata, num=n_samples, t=timestamps, window='hann')\n",
    "        \n",
    "\n",
    "    if filtering:\n",
    "        # filter the signal block with low-pass filter\n",
    "        testdata = butter_lowpass_filter(testdata, cutoff, fs, order)\n",
    "        \n",
    "    return testdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Crossing Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_zero_crossings(datablock, normalized=False):\n",
    "    '''computes row-wise zerocrossings'''\n",
    "    # datablock is assumed to be pandas Dataframe and to have multiple signals in the rows\n",
    "    # example for 1 signal row:\n",
    "    #zcr = np.signbit(signal).diff().abs().mean()\n",
    "    # for multiple signal rows:\n",
    "    zcr = np.signbit(datablock).astype(int).diff(axis=0).abs().mean(axis=0)\n",
    "    \n",
    "    if normalized:\n",
    "        # divide by length of signal, otherwise it will be directly related to the size of the chosen window\n",
    "        zcr = zcr / datablock.shape[0]\n",
    "    return zcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calc statistical features\n",
    "\n",
    "def calc_statistical_features(matrix, axis=0):\n",
    "\n",
    "    # to define the proper output shape, we need the \"other axis\" of the input shape (not the one where we compute along)\n",
    "    other_axis = int(not axis) \n",
    "    n_rows = matrix.shape[other_axis]\n",
    "    \n",
    "    result = np.zeros((n_rows,7))\n",
    "    \n",
    "    result[:,0] = np.mean(matrix, axis=axis)\n",
    "    result[:,1] = np.var(matrix, axis=axis, dtype=np.float64) \n",
    "    result[:,2] = stats.skew(matrix, axis=axis)\n",
    "    result[:,3] = np.median(matrix, axis=axis)\n",
    "    result[:,4] = np.min(matrix, axis=axis)\n",
    "    result[:,5] = np.max(matrix, axis=axis)\n",
    "    result[:,6] = stats.kurtosis(matrix, axis=axis, fisher=False) # Matlab calculates Pearson's Kurtosis\n",
    "\n",
    "    result[np.where(np.isnan(result))] = 0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Spectrum (~ FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: set window size to something like 1/2 or 1/3 of the smallest gesture\n",
    "\n",
    "def compute_power_spectrum_avg(signal_data, window_size=100):   # window_size=360\n",
    "    '''signal_data: numpy array, rows: time, columns: different signals\n",
    "    computes power spectrum of each signal, in a windowed manner\n",
    "    aftewards the power spectrums of each window per signal are averaged'''\n",
    "    \n",
    "    if window_size > len(signal_data):\n",
    "        raise ValueError(\"Window is bigger than input signal: \" + str(len(signal_data)))\n",
    "    \n",
    "    hop_size = int(window_size / 2)\n",
    "\n",
    "    power_spec_list = []\n",
    "\n",
    "    pos = 0\n",
    "    while pos + window_size <= len(signal_data):\n",
    "        #print pos, pos+window_size\n",
    "        sig_window = signal_data[pos:pos+window_size]\n",
    "        # for periodogram we need to transpose to compute the signal along the right axis\n",
    "        freq_axis, power_spec = periodogram(sig_window.T, fs=sampling_rate, window='hann') \n",
    "        power_spec_list.append(power_spec)\n",
    "        pos += hop_size\n",
    "\n",
    "    power_spec_array = np.array(power_spec_list)  \n",
    "    power_spec_avg = np.mean(power_spec_array, axis=0)\n",
    "    return power_spec_avg, freq_axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to compute All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_all_features(in_data, calc_derivative=False, calc_zerocrossings=False, calc_power_spectrum=False):\n",
    "\n",
    "    # calc statistical features\n",
    "    features = calc_statistical_features(in_data, axis=0)\n",
    "\n",
    "    # vectorize\n",
    "    features = features.flatten()\n",
    "\n",
    "    if calc_derivative:\n",
    "        # calc derivative of all signals\n",
    "        in_data_deriv = np.gradient(in_data, axis=0)\n",
    "        # calc statistics of derivatives\n",
    "        features_deriv = calc_statistical_features(in_data_deriv, axis=0)\n",
    "        # vectorize\n",
    "        features_deriv = features_deriv.flatten()\n",
    "        # concatenate to other features\n",
    "        features = np.concatenate((features,features_deriv))\n",
    "\n",
    "    if calc_zerocrossings:\n",
    "        features_zcr = calc_zero_crossings(in_data)\n",
    "        features = np.concatenate((features,features_zcr))\n",
    "        \n",
    "    if calc_power_spectrum:\n",
    "        power_spec_avg, freq_axis = compute_power_spectrum_avg(in_data)\n",
    "        # combine spectrum of all signals into 1 long vector\n",
    "        power_spec_avg = power_spec_avg.flatten()\n",
    "        features = np.concatenate((features,power_spec_avg))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Feature Calculation\n",
    "\n",
    "### Set Options here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OPTIONS:\n",
    "\n",
    "# want non_gestures in result? can use option depending on replace_nestures True or False, or exclude always\n",
    "exclude_non_gestures = replace_nestures  # True\n",
    "\n",
    "# preprocessing options\n",
    "use_lowpassfilter = False     # apply low-pass filter (filtering out high frequencies) - settings see above\n",
    "use_normalized = True         # local normalization, per each window!\n",
    "use_resampled = True          # resample time signal to common window length (see samples parameter)\n",
    "# 2 choices for resampling:\n",
    "# a) just re-align by given timestamps to equi-distant timestamps, but same number of samples are kept:\n",
    "n_samples = None\n",
    "# b) resample ALL gestures to a FIXED common number of samples given here:\n",
    "#n_samples = int(gest_len_avg)   # we choose the average gesture length for the common resampled gesture length\n",
    "\n",
    "# override use_normalized: if we already normalized globally, we should not do it again locally\n",
    "if normalize_global: use_normalized = False\n",
    "\n",
    "# feature options: # True is better for all, except Power spectrum\n",
    "calc_derivative = True\n",
    "calc_zerocrossings = True\n",
    "calc_powerspectrum = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we added preprocess_signal() function below, thats why we need to use the original gesture_dict as input\n",
    "input_dict = gesture_exp_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if exclude_non_gestures:\n",
    "    gestures_to_process = gestures_pos\n",
    "else:\n",
    "    gestures_to_process = input_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gestures_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# COMPUTE FEATURES\n",
    "# LOOP over all gesture data to create features\n",
    "\n",
    "# initialize feature output for training data as a list\n",
    "train_list = []\n",
    "train_classes_num = []\n",
    "\n",
    "# iterate over gesture number\n",
    "for gest in sorted(gestures_to_process):\n",
    "    print \"G\", gest, ':\\t', len(input_dict[gest]), \"examples\"\n",
    "    \n",
    "    # iterate over all gesture blocks for that gesture number\n",
    "    for in_data in input_dict[gest]:\n",
    "        #print datablock.shape, \n",
    "        \n",
    "        #if use_resampled:\n",
    "        #    # resampled data has already extracted the param columns\n",
    "        #    in_data = datablock\n",
    "        #else:\n",
    "        #    # for non-resampled we have to get the relevant data columns and transpose\n",
    "        #    in_data = datablock[params].T\n",
    "        \n",
    "        # preprocessing\n",
    "        in_data = preprocess_signal(in_data, use_normalized, \n",
    "                                    use_resampled, n_samples, timestamps=None, window=None, # 'hann'\n",
    "                                    filtering=use_lowpassfilter)\n",
    "                \n",
    "        # convert to dataframe cause we use pandas .diff() in ZCR computation\n",
    "        in_data = pd.DataFrame(in_data, columns=params)\n",
    "\n",
    "        # calculate features\n",
    "        features = calc_all_features(in_data, calc_derivative, calc_zerocrossings, calc_powerspectrum)\n",
    "\n",
    "        # append to output list\n",
    "        train_list.append(features)\n",
    "        \n",
    "        # store class (gesture number) for these features\n",
    "        train_classes_num.append(gest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Feature vector length:\", len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print \"Training data:\", len(train_list), \"examples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make feature array from feature list (ALL training data)\n",
    "train_data = np.array(train_list)\n",
    "del train_list # not needed any longer\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# verify if the training categories (gesture numbers) have the same length\n",
    "len(train_classes_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize\n",
    "\n",
    "Zero-mean unit-variance Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ad-hoc scaling\n",
    "# train_data = preprocessing.scale(train_data,axis=0)\n",
    "# axis=0 means independently standardize each feature, otherwise (if 1) standardize each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we now user StandardScaler class to keep the mean and variance for later\n",
    "standardizer = preprocessing.StandardScaler()\n",
    "train_data = standardizer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Set Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the data into train/test set\n",
    "\n",
    "testset_size = 0.25\n",
    "\n",
    "# sklearn >= 0.18\n",
    "# use random_state to avoid that the results fluctuate randomly\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=testset_size, random_state=0) \n",
    "splits = splitter.split(train_data, train_classes_num)\n",
    "\n",
    "# Note: this for loop is only executed once, if n_splits==1\n",
    "for train_index, test_index in splits:\n",
    "    #print \"TRAIN INDEX:\", train_index\n",
    "    #print \"TEST INDEX:\", test_index\n",
    "    \n",
    "    # split the data\n",
    "    train_set = train_data[train_index]\n",
    "    test_set = train_data[test_index]\n",
    "    \n",
    "    # and the numeric classes (groundtruth)\n",
    "    train_classes = np.array(train_classes_num)[train_index]\n",
    "    test_classes = np.array(train_classes_num)[test_index]\n",
    "    \n",
    "    print \"TRAIN SIZE:\", train_set.shape\n",
    "    print \"TEST SIZE:\", test_set.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Gesture Regonition - isolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Algorithm: SVM\n",
    "\n",
    "Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try 3 different SVM kernels\n",
    "kernels = ['linear','poly','rbf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    print \"SVM\", kernel,\n",
    "    \n",
    "    # TRAIN \n",
    "    start_time = time.time() # measure time\n",
    "\n",
    "    model = OneVsRestClassifier(SVC(kernel=kernel)) #, degree=degree)) #, n_jobs=-1)  # n_jobs = n cpus, -1 = all\n",
    "    # full set\n",
    "    #model.fit(train_data, train_classes_num)\n",
    "    # train set\n",
    "    model.fit(train_set, train_classes)\n",
    "    \n",
    "    # store in dict\n",
    "    models[kernel] = model\n",
    "\n",
    "    end_time = time.time()\n",
    "    print \"Training time:\", timestr(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verification on Train Set (just for plausibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict on train set (will reuse last model == rbf only)\n",
    "pred_train = model.predict(train_set)\n",
    "# print pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print train_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accuracy on train set (manual computation)\n",
    "np.sum(pred_train == train_classes) * 1.0 / len(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Accuracy on train set (using scikit-learn)\n",
    "accuracy_score(train_classes, pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_ov = pd.DataFrame(index=kernels, columns=['Accuracy','Precision','Recall','F-Measure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in kernels:\n",
    "    # predict on TEST set\n",
    "    pred_test = models[k].predict(test_set) \n",
    "    \n",
    "    # Accuracy, Precision, Reacall on TEST set\n",
    "    result_ov.loc[k,'Accuracy'] = accuracy_score(test_classes, pred_test)\n",
    "    result_ov.loc[k,'Precision'] = precision_score(test_classes, pred_test, average='macro')\n",
    "    result_ov.loc[k,'Recall'] = recall_score(test_classes, pred_test, average='macro')\n",
    "    result_ov.loc[k,'F-Measure'] = f1_score(test_classes, pred_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "result_ov*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - Per Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# manual selection which one was the best one\n",
    "best_model = models['poly']\n",
    "pred_test = best_model.predict(test_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO check if the sorting of precision_score etc. is really in this order!!\n",
    "labels = sorted(np.unique(test_classes))\n",
    "gesture_names = [gesture_name(l) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nice result dataframe\n",
    "columns = ['Gesture','N_train','N_test','Precision','Recall','F1']\n",
    "result_df = pd.DataFrame(index=labels,columns=columns)\n",
    "result_df['Gesture'] = gesture_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of train / test instances\n",
    "values, counts = np.unique(train_classes, return_counts=True)\n",
    "result_df['N_train'] = pd.Series(counts, index=values)\n",
    "values, counts = np.unique(test_classes, return_counts=True)\n",
    "result_df['N_test'] = pd.Series(counts, index=values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# per class evaluation\n",
    "result_df['Precision'] = precision_score(test_classes, pred_test, average=None) * 100\n",
    "result_df['Recall'] = recall_score(test_classes, pred_test, average=None) * 100\n",
    "result_df['F1'] = f1_score(test_classes, pred_test, average=None) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compare average P, R and F to overall P, R and F above (same)\n",
    "result_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf = confusion_matrix(test_classes, pred_test, labels=labels) # labels defines the order\n",
    "labels_long = gestures_df.loc[labels,'name']\n",
    "conf_df = pd.DataFrame(conf, index=labels_long, columns=labels)\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2) Continuous Time Series Prediction\n",
    "\n",
    "What is our input stream?\n",
    "\n",
    "The data of 1 trainset, because after each trainset, the TimeStamp is reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a) loop over each Trainset\n",
    "#group_by = ('Subject','Experiment','Trainset')\n",
    "\n",
    "# b) use Experiment as the block where we do predictions (means it includes timestamp resets!!)\n",
    "group_by = ('Subject','Experiment')\n",
    "\n",
    "group_df = data.groupby(group_by)\n",
    "group_df.max().head(50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(group_df), \"Experiments / Trainsets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterate over each Trainset\n",
    "i =0\n",
    "for name_tuple, group_data in group_df:\n",
    "    i += 1\n",
    "    #print str(name_tuple)\n",
    "    \n",
    "    if len(name_tuple) == 3:\n",
    "        subject, exp, trainset = name_tuple\n",
    "    elif len(name_tuple) == 2:\n",
    "        subject, exp = name_tuple\n",
    "        trainset = None\n",
    "    \n",
    "    break # for testing we just do 1 loop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_data['TimeStamp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_data['TimeStamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if len(name_tuple) == 3:\n",
    "    # check if TimeStamps are monotonously increasing\n",
    "    if not np.all(group_data['TimeStamp'].diff()[1:] > 0):\n",
    "        raise ValueError(\"Time Stamps are not monotonously increasing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set these to None so that plot title is not shown wrongly\n",
    "parcours = None\n",
    "mutation = None\n",
    "gesture = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# which gestures appear in this Experiment or Trainset\n",
    "group_data['Gesture'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Process the Data - Testing\n",
    "\n",
    "the same way as it was done for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the relevant columns out of group_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamps = group_data['TimeStamp'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gestures = group_data['Gesture'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 9 parameters columns\n",
    "testdata = group_data[params]\n",
    "testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global Min/max normalization\n",
    "# Note: to do it the fully right way, the minmax scaling should be done on all training data coherently\n",
    "# (currently its done per training block) and the same scaling values (min and max) should be reused here\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "# TODO store minmax_scale from training data and reapply same scaling here\n",
    "\n",
    "if normalize_global:\n",
    "    testdata = preprocessing.minmax_scale(testdata, feature_range=(-1, 1), axis=0, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to dataframe cause plot needs column names\n",
    "testdata = pd.DataFrame(testdata, columns=params)\n",
    "testdata.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# time resample\n",
    "\n",
    "n_samples = len(timestamps)  \n",
    "\n",
    "if use_resampled:\n",
    "    # the number of samples stays the same\n",
    "    # but we use the original timestamps to re-align the signal\n",
    "    testdata_res, timestamps2 = resample(testdata, num=n_samples, t=timestamps)\n",
    "    \n",
    "    # convert to dataframe cause plot needs column names\n",
    "    testdata_res = pd.DataFrame(testdata_res, columns=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamps[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamps2[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# timestamps are now equidistant\n",
    "timestamps2[1:15] - timestamps2[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdata_res.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# debug check whether the values have been altered -> OK\n",
    "#testdata == testdata_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# overwrite testdata with testdata_res for subsequent coherent usage\n",
    "#testdata = testdata_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for our window_size (= signal length of input to Machine Learning)\n",
    "# we take the average signal length of the trained gestures\n",
    "window_size = int(gest_len_avg) # gest_len_min \n",
    "window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PREDICTION RESOLUTION\n",
    "# how quickly do we step forward\n",
    "\n",
    "# for now we choose half the window_size\n",
    "#step_size = window_size / 2\n",
    "\n",
    "# for speedup we choose same as window_size\n",
    "step_size = window_size \n",
    "\n",
    "# can be set smaller for higher resolution\n",
    "\n",
    "# TODO: set in milliseconds - convert back to sample length\n",
    "\n",
    "step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Testing in continous signal with %.3f sec window and %.3f sec step size\" % (window_size * time_delta_sec, \n",
    "                                                                                  step_size * time_delta_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: align with preprocess_signal function used in training data above\n",
    "\n",
    "def preprocess_signal_continuous(testdata, normalize=False, resampling=False, timestamps=None, filtering=False):\n",
    "    \n",
    "    # Min/max normalization\n",
    "    # Note: to do it the fully right way, the minmax scaling should be done on all training data coherently\n",
    "    # (currently its done per training block) and the same scaling values (min and max) should be reused here\n",
    "    # see http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "    if normalize:\n",
    "        testdata = preprocessing.minmax_scale(testdata, feature_range=(-1, 1), axis=0)\n",
    "        \n",
    "    # Time Resampling\n",
    "    if resampling:\n",
    "        # the number of samples stays the same\n",
    "        # if provided, we use the original timestamps to re-align the signal\n",
    "        n_samples = testdata.shape[0] # must match len(timestamps)\n",
    "        testdata, timestamps2 = resample(testdata, num=n_samples, t=timestamps) #, window='hann')\n",
    "\n",
    "    if filtering:\n",
    "        # filter the signal block with low-pass filter\n",
    "        testdata = butter_lowpass_filter(testdata, cutoff, fs, order)\n",
    "        \n",
    "    return testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PREDICTION LOOP OVER 1 TRAINING INPUT BLOCK\n",
    "\n",
    "def continuous_prediction(testdata, test_gestures, window_size, step_size):\n",
    "    pos = 0\n",
    "    n_samples = testdata.shape[0]\n",
    "    \n",
    "    # output\n",
    "    test_groundtruth = [] # we create the groundtruth to compare with here\n",
    "    predictions = []  # predictions are collected here\n",
    "\n",
    "    while pos < (n_samples - window_size):\n",
    "        # 1) DETERMINE GROUNDTRUTH (for evaluation only, not used in predictions)\n",
    "        \n",
    "        # to get the \"correct\" gesture for that window, we cut the same part of the gesture information\n",
    "        test_window_groundtruth = test_gestures[pos:pos+window_size]\n",
    "\n",
    "        # HOW to determine groundtruth?\n",
    "        # a) determine gesture from the window center\n",
    "        gt_gesture = test_gestures[pos+(window_size/2)]\n",
    "        \n",
    "        # b) Majority vote: which is the predominant label in the whole window\n",
    "        #gt_gesture = Counter(test_window_groundtruth).most_common()[0][0]\n",
    "\n",
    "        # 2) DO PREDICTIONS\n",
    "        \n",
    "        # cut a window out of the incoming signal\n",
    "        signal = testdata[pos:pos+window_size]\n",
    "\n",
    "        # calc features\n",
    "        features = calc_all_features(signal, calc_derivative, calc_zerocrossings)\n",
    "\n",
    "        # reshape to row vector for standardize and predict below (= single input sample)\n",
    "        features = features.reshape(1, -1)  \n",
    "        \n",
    "        # STANDARDIZE features, the same way as done in training (reusing those mean and var)\n",
    "        features = standardizer.transform(features)\n",
    "\n",
    "        # ML prediction of gesture\n",
    "        pred_gesture = best_model.predict(features)[0]\n",
    "\n",
    "        # add to groundtruth and prediction list\n",
    "        test_groundtruth.append(gt_gesture)\n",
    "        predictions.append(pred_gesture)\n",
    "\n",
    "        # step forward\n",
    "        pos += step_size\n",
    "    \n",
    "    return test_groundtruth, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOOP over ALL Experiments or Trainsets\n",
    "\n",
    "i = 0\n",
    "n_groups = len(group_df)\n",
    "\n",
    "test_groundtruth_all = [] # we create the groundtruth to compare with here\n",
    "predictions_all = []  # predictions are collected here\n",
    "\n",
    "for name_tuple, group_data in group_df:\n",
    "    \n",
    "    i += 1\n",
    "    print \"Experiment\", i, \"/\", n_groups, \":\", str(name_tuple), group_data.shape,\n",
    "    \n",
    "    # just metadata\n",
    "    if len(name_tuple) == 3:\n",
    "        subject, exp, trainset = name_tuple\n",
    "    elif len(name_tuple) == 2:\n",
    "        subject, exp = name_tuple\n",
    "        trainset = None\n",
    "    \n",
    "    # get signals, timestamps and gesture groundtruth\n",
    "    timestamps = group_data['TimeStamp'].tolist()   # timestamps\n",
    "    testdata = group_data[params]                   # signals\n",
    "    test_gestures = group_data['Gesture'].tolist()  # groundtruth\n",
    "    \n",
    "    # preprocess testdata\n",
    "    print \"Preprocessing ...\",\n",
    "    testdata = preprocess_signal_continuous(testdata, use_normalized, use_resampled, timestamps, use_lowpassfilter)\n",
    "    #print testdata.shape\n",
    "    \n",
    "    # convert to dataframe cause we use pandas .diff() in ZCR computation\n",
    "    testdata = pd.DataFrame(testdata, columns=params)\n",
    "    \n",
    "    print \"Prediction:\", \n",
    "    test_groundtruth, predictions = continuous_prediction(testdata, test_gestures, window_size, step_size)\n",
    "    print len(predictions), \"predictions\"\n",
    "    \n",
    "    test_groundtruth_all.extend(test_groundtruth)\n",
    "    predictions_all.extend(predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(predictions_all), \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"collected true gestures include:\"\n",
    "np.unique(test_groundtruth_all).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"predicted gestures include:\"\n",
    "np.unique(predictions_all).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'groundt':test_groundtruth_all, 'pred':predictions_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_ov = pd.DataFrame(columns=['result']) #columns=['Accuracy','Precision','Recall','F-Measure'])\n",
    "\n",
    "# Accuracy, Precision, Reacall on TEST set\n",
    "result_ov.loc['Accuracy'] = accuracy_score(test_groundtruth_all, predictions_all)\n",
    "result_ov.loc['Precision'] = precision_score(test_groundtruth_all, predictions_all, average='macro')\n",
    "result_ov.loc['Recall'] = recall_score(test_groundtruth_all, predictions_all, average='macro')\n",
    "result_ov.loc['F-Measure'] = f1_score(test_groundtruth_all, predictions_all, average='macro')\n",
    "result_ov = result_ov * 100\n",
    "result_ov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_long = gestures_df.loc[labels,'name']\n",
    "conf = confusion_matrix(test_groundtruth_all, predictions_all, labels=labels) # labels defines the order\n",
    "conf_df = pd.DataFrame(conf, index=labels_long, columns=labels)\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
